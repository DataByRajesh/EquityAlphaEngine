
# ğŸ“Š EquityAlphaEngine - Local Deployment Guide

## Project Overview

**EquityAlphaEngine** is a UK Equity Analytics Platform that:
- Fetches financial fundamentals and historical data
- Computes multi-factor scoring models
- Caches data locally with expiry control
- Provides an interactive stock screener via Streamlit
- Sends Gmail alerts on data pipeline events

---

## âœ… Local Deployment Checklist

### 1ï¸âƒ£ Clone the Project Locally
```
git clone <your-repo-url>
cd EquityAlphaEngine/data_pipeline
```

### 2ï¸âƒ£ Set Up Virtual Environment (Optional but Recommended)
```
python -m venv env
source env/bin/activate  # or env\Scripts\activate on Windows
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure Your `config.py`
- âœ… Check your database path (`DB_PATH`)
- âœ… Set your cache expiry settings
- âœ… Ensure your Gmail credentials are correct (optional for alerts)

### 4ï¸âƒ£ Initialize Cache & Database (Optional)
- Cache will create itself on first run
- SQLite database should exist or be created by `UK_data.py`

---

## âœ… Running the Data Pipeline Locally
This will fetch data, compute factors, and update the database.
```
python UK_data.py --start_date 2020-01-01 --end_date 2025-07-17
```

---

## âœ… Running the Streamlit Screener Locally
From inside `data_pipeline/` folder:
```
streamlit run streamlit_screener.py
```

- ğŸ›ï¸ Use sidebar filters to refine your stock list
- ğŸ“ˆ View multi-factor rankings and charts
- ğŸ’¾ Download the output CSV

---

## âœ… Notes on Cache & Data Persistence
- Cache backend configurable via environment variables:
  - `CACHE_BACKEND` â€“ `local` (default), `redis` or `s3`
  - `CACHE_REDIS_URL` â€“ Redis connection string when using the Redis backend
  - `CACHE_S3_BUCKET` / `CACHE_S3_PREFIX` â€“ S3 bucket (and optional key prefix)
- Local JSON cache is used when `CACHE_BACKEND` is `local` (`cache_utils.py`)
- SQLite database stores computed financials (`data/stocks_data.db`)
- Gmail alerts use credentials from `credentials.json` (optional)

---

## â˜ï¸ Persistent Storage Recommendations
For deployments requiring durable storage of datasets or logs, point the
`DATA_DIR`, `CACHE_DIR`, and `LOG_DIR` environment variables to cloud object
storage such as:

- **Amazon S3**
- **Supabase Storage**

These services keep pipeline outputs across restarts and can be mounted or
accessed via SDKs, allowing the application to treat them like local folders.

---

## âœ… When Ready for Cloud Deployment
- Switch to a hosted DB like Supabase/PostgreSQL
- Consider using an online cache or removing file-based cache
- Set up environment variables for sensitive credentials

---

## ğŸ“ Author's Note
This guide assumes a local dev environment.
Use this setup for testing, development, and proof of concept.

---

## âœ… Project by Rajesh Kumar Alagesan
